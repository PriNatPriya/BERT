{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://programmerbackpack.com/bert-nlp-using-distilbert-to-build-a-question-answering-system/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from question_processor import QuestionProcessor\n",
    "from text_extractor import TextExtractor\n",
    "from text_extractor_pipe import TextExtractorPipe\n",
    "from context_retriever import ContextRetriever\n",
    "from answer_retriever import AnswerRetriever\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "originalQuestion----------- What is the capital city of Romania?\n",
      "questionContext***************** None\n",
      "capital city Romania\n",
      "encodings_____________________ {'input_ids': [101, 2054, 2003, 1996, 3007, 2103, 1997, 6339, 1029, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
      "input_ids______________________ [101, 2054, 2003, 1996, 3007, 2103, 1997, 6339, 1029, 102]\n",
      "scoresStart--------- start_logits\n",
      "scoresEnd------- end_logits\n",
      "torch.tensor([inputIds]---------------------------- tensor([[ 101, 2054, 2003, 1996, 3007, 2103, 1997, 6339, 1029,  102]])\n",
      "torch.tensor([attentionMask])----------------------- tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "argmax(): argument 'input' (position 1) must be Tensor, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-b4ae216d1d95>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"questionContext*****************\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mquestionContext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mquestionProcessor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moriginalQuestion\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m \u001b[0manswer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0manswerRetriever\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetAnswer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moriginalQuestion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mquestionContext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\work\\bert\\answer_retriever.py\u001b[0m in \u001b[0;36mgetAnswer\u001b[1;34m(self, question, questionContext)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;31m#         print(\"attention_mask--------------------\",attention_mask)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m         \u001b[0mtokens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minputIds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscoresStart\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscoresEnd\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m         \u001b[0manswerTokens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdistilBertTokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_ids_to_tokens\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mskip_special_tokens\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mdistilBertTokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_tokens_to_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0manswerTokens\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: argmax(): argument 'input' (position 1) must be Tensor, not str"
     ]
    }
   ],
   "source": [
    "textExtractor1 = TextExtractor(\"London\", \"Q84\")\n",
    "textExtractor1.extract()\n",
    "textExtractor2 = TextExtractor(\"Berlin\", \"Q64\")\n",
    "textExtractor2.extract()\n",
    "textExtractor3 = TextExtractor(\"Bucharest\", \"Q19660\")\n",
    "textExtractor3.extract()\n",
    "\n",
    "textExtractorPipe = TextExtractorPipe()\n",
    "textExtractorPipe.addTextExtractor(textExtractor1)\n",
    "textExtractorPipe.addTextExtractor(textExtractor2)\n",
    "textExtractorPipe.addTextExtractor(textExtractor3)\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "nlp.add_pipe(nlp.create_pipe('sentencizer'))\n",
    "doc = nlp(textExtractorPipe.extract())\n",
    "sentences = [sent.string.strip() for sent in doc.sents]\n",
    "questionProcessor = QuestionProcessor(nlp)\n",
    "contextRetriever = ContextRetriever(nlp, 10)\n",
    "answerRetriever = AnswerRetriever()\n",
    "\n",
    "originalQuestion = \"What is the capital city of Romania?\"\n",
    "questionContext = contextRetriever.getContext(sentences, questionProcessor.process(originalQuestion))\n",
    "print (\"originalQuestion-----------\",originalQuestion)\n",
    "print(\"questionContext*****************\",questionContext)\n",
    "print (questionProcessor.process(originalQuestion))\n",
    "answer = answerRetriever.getAnswer(originalQuestion, questionContext)\n",
    "print (answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertTokenizer, DistilBertForQuestionAnswering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnswerRetriever:\n",
    "\n",
    "    def getAnswer(self, question, questionContext):\n",
    "        distilBertTokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased', return_token_type_ids=True)\n",
    "        distilBertForQuestionAnswering = DistilBertForQuestionAnswering.from_pretrained(\n",
    "            'distilbert-base-uncased-distilled-squad')\n",
    "\n",
    "        encodings = distilBertTokenizer.encode_plus(question, questionContext)\n",
    "        print(\"encodings_____________________\",encodings)\n",
    "        print(\"input_ids______________________\",encodings[\"input_ids\"])\n",
    "        print(\"attention_mask__________________\",encodings[\"attention_mask\"])\n",
    "\n",
    "        inputIds, attentionMask = encodings[\"input_ids\"], encodings[\"attention_mask\"]\n",
    "        distilBertTokenizer\n",
    "\n",
    "        scoresStart, scoresEnd = distilBertForQuestionAnswering(torch.tensor([inputIds]),attention_mask=torch.tensor([attentionMask]))\n",
    "        print(\"torch.tensor([inputIds]----------------------------\",torch.tensor([inputIds]))\n",
    "        print(\"torch.tensor([attentionMask])-----------------------\",torch.tensor([attentionMask]))\n",
    "        print(\"attention_mask--------------------\",attention_mask)\n",
    "\n",
    "        tokens = inputIds[torch.argmax(scoresStart): torch.argmax(scoresEnd) + 1]\n",
    "        answerTokens = distilBertTokenizer.convert_ids_to_tokens(tokens, skip_special_tokens=True)\n",
    "        return distilBertTokenizer.convert_tokens_to_string(answerTokens)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
